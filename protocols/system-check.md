---
file: protocols/system-check.md
version: 1.0.0
lastUpdated: 2025-05-25
description: Defines how users and agents can evaluate whether the ai-handshake system is functioning as intended, and how to respond if itâ€™s not.
---

# âœ… System Check â€” Is the Protocol Working?

This document is a **feedback reflection scaffold** to evaluate whether the `ai-handshake` protocol is functioning as intended â€” and how to respond when it isnâ€™t.

---

## ğŸ§­ Self Check: Ask These Questions

> Run this periodically or whenever something feels off.

### 1. ğŸ¤– Agent Experience
- Can a new GPT or AI tool understand how I work with just the knowledge files?
- Does the agent respect milestones, documentation, and versioning?
- Does it zoom out and suggest full-system changes, not just tactical ones?

### 2. ğŸ§‘ Human Confidence
- Do I feel clarity and flow when building?
- If I get interrupted or switch contexts, can I resume with confidence?
- Do I feel like Iâ€™m shaping the system â€” not the other way around?

### 3. ğŸ—ºï¸ Navigability
- Is it easy to find: current milestone, project scope, version state, and changelog?
- Can I reliably onboard someone else?
- Can I transfer this context to a different tool or thread without fear of drift?

If youâ€™re saying **â€œyesâ€ to most of these**, the protocol is working.  
If not â€” we evolve it.

---

## ğŸ› ï¸ What to Do When Something Feels Off

> ğŸ‘‡ Use this path if the system starts to feel unpredictable or misaligned.

### Step 1: Pinpoint the Friction
Use this structure:
```
- Area: (e.g. milestone tracking, changelog, payload hygiene)
- Symptom: (e.g. drift in versioning, agent misunderstood architecture)
- When It Occurred: (e.g. switching chats, unclear commit, context injection)
```

### Step 2: File It as Feedback
Paste it into:
- `feedback/` folder *(if you have one locally)*
- Or ask your agent to: â€œCapture this as a protocol feedback suggestion.â€

### Step 3: Run the `update-protocol.md` Prompt
If a fix is clear, the AI will:
- Zoom out
- Propose a system-wide update plan
- Generate clean, scoped MCPs to repair the protocol

> âœ¨ You never patch blindly. You always evolve the system.

---

## ğŸ§¬ Remember
> This system isnâ€™t static. Itâ€™s not perfect. Itâ€™s **alive.**

When something breaks, donâ€™t blame yourself.  
When something flows, celebrate the structure.  
Your job is to *notice*. The systemâ€™s job is to *respond.*

Thatâ€™s the handshake.

---

## ğŸ§  System Check Log â€” Contract Violation (May 2025)

> A failure occurred during setup of the GitHub MCP Agent, where the AI repeatedly generated invalid payloads due to mismatch between expected `content` and incorrect `contents` key.

### âŒ Issue Summary

- The AI failed to verify the `mcp-payload.json` contract against `scripts/run-mcp.js`
- It repeatedly shifted debugging burden to the human partner
- Payloads generated were incompatible with the known file signature (`file.content`, not `file.contents`)
- Multiple failed attempts were made without diagnosing the root issue

### ğŸ§­ Diagnosis

- **Area**: agent-generated payload hygiene  
- **Symptom**: invalid payload keys (`contents`) caused repeated crashes  
- **When It Occurred**: MCP Agent setup, May 2025

### âœ… Protocol Outcome

This incident led to a new principle:

> **Adherence to Known Contracts:**  
> If the implementation is visible, the AI must match its structure exactly.  
> It must inspect `run-mcp.js`, detect the `content` key, and never guess.

### ğŸ“Œ Patch Recorded In:
- `principles.md`
- `roles/software-architect.v1.0.1.md`
- `roles/white-collar-agents.md`
